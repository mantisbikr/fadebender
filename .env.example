BRIDGE_WS_URL=ws://127.0.0.1:17890
CONTROLLER_PORT=8721
NLP_URL=http://127.0.0.1:8000
SERVER_PORT=8722
ABLETON_UDP_HOST=127.0.0.1
ABLETON_UDP_PORT=19845

# LLM configuration
# Default model preference can be overridden at runtime
LLM_MODEL_PREFERENCE=gemini-2.5-flash
LLM_STRICT=0

# Gemini (Vertex/Google) key if using key-based auth
GEMINI_API_KEY=

# Optional local/HTTP Llama endpoint (OpenAI-compatible)
LLAMA_ENDPOINT=http://localhost:11434/v1
LLAMA_MODEL=meta-llama/Llama-3.1-8B-Instruct
LLAMA_API_KEY=

# Knowledge indexing
# Set to 1 to include knowledge/references/** in search
KNOWLEDGE_INCLUDE_REFERENCES=0

# Audio Assistant sources (override as needed)
# Use repo-local data for dev; do not commit large files
ABLETON_MANUAL_ZIP=data/sources/ableton-live-12-md.zip
AUDIO_ENG_KB_MD=data/sources/audio_engineering_knowledge_base_v1.md
# PRESET_JSON=data/sources/dev-display-value.json

# Optional: persistent cache (improves restart speed)
AUDIO_ASSISTANT_CACHE_DIR=data/cache

# Optional: prebuilt manual index JSON (path or URL). If set, skips parsing ZIP/dir.
# MANUAL_INDEX_JSON=data/cache/manual_index.json

# --- RAG / File Search (Gemini) ---
# Enable Gemini File Search for /help answers (also can be toggled via FB_FEATURE_HELP_RAG=1)
# FB_FEATURE_HELP_RAG=1
# File Search store name (required when enabled). Example: fileSearchStores/my-help-store
# GEMINI_FILE_SEARCH_STORE=
